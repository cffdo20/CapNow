{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209c6766-9d28-4ecc-8fff-22099532a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "import numpy as np\n",
    "from tkinter import filedialog, Toplevel, Canvas, Button, Frame\n",
    "from PIL import Image, ImageTk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daa6811a-3158-4825-b799-af730c6b1bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Digite o caminho da pasta com o vídeo:  C:\\Users\\PC\\Documents\\documents\\ifam\\TETI\\Listas_Atividades\\Trabalho_Manipulacao_Videos\\teti_imagens\n",
      "Digite o nome do arquivo de vídeo:  mont_russa.mp4\n",
      "Digite o caminho da pasta para onde os frames salvos irão:  C:\\Users\\PC\\Documents\\documents\\ifam\\TETI\\Listas_Atividades\\Trabalho_Manipulacao_Videos\\teti_imagens\\frames\n"
     ]
    }
   ],
   "source": [
    "path_img = input(\"Digite o caminho da pasta com o vídeo: \").replace('\\\\', '/') + '/'\n",
    "video = path_img + input(\"Digite o nome do arquivo de vídeo: \")\n",
    "frames_folder = input(\"Digite o caminho da pasta para onde os frames salvos irão: \").replace('\\\\', '/') + '/'\n",
    "path = os.getcwd() + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faf02223-c319-46ae-88bc-5d36de6bb3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = np.array([[-1, -1, -1],[-1, 9, -1],[-1, -1, -1]])\n",
    "k2 = np.array([[1, 0, 0],[0, 0, 0],[0, 0, -1]])\n",
    "k3 = np.array([[0, 0, 0],[0, 1, 0],[0, 0, 0]])\n",
    "k4 = np.array([[0, -1, 0],[-1, 5, -1],[0, -1, 0]])\n",
    "k_blur = np.array([[1/9, 1/9, 1/9],[1/9, 1/9, 1/9],[1/9, 1/9, 1/9]], dtype=np.float32)\n",
    "k_sharpen = np.array([[0, -1, 0],[-1, 5, -1],[0, -1, 0]], dtype=np.float32)\n",
    "k_emboss = np.array([[2, 1, 0],[1, 0, -1],[0, -1, -2]], dtype=np.float32)\n",
    "k_laplace = np.array([[0,1,0],[1,-4,1],[0,1,0]], dtype = np.float32)\n",
    "k_sobel_x = np.array([[-1, 0, 1],[-2, 0, 2],[-1, 0, 1]], dtype=np.float32)\n",
    "k_sobel_y = np.array([[1, 2, 1],[0, 0, 0],[-1, -2, -1]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3038eea-a066-4369-8f5c-290d0760e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modo_def(frame, modo):\n",
    "    if modo == 'gray':\n",
    "         frame_alterado = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    elif modo == 'binary':\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        _, frame_alterado = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "    elif modo == 'laplace':\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_alterado = cv2.filter2D(gray, -1, k_laplace)\n",
    "    elif modo == 'blur':\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_alterado = cv2.filter2D(gray, -1, k_blur)\n",
    "    elif modo == 'sharpen':\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_alterado = cv2.filter2D(gray, -1, k_sharpen)\n",
    "    elif modo == 'emboss':\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_alterado = cv2.filter2D(gray, -1, k_emboss)\n",
    "    elif modo == 'edges':\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_alterado = cv2.Canny(gray, 100, 200)\n",
    "    elif modo == 'sobel-x':\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_alterado = cv2.filter2D(gray, -1, k_sobel_x)\n",
    "    elif modo == 'sobel-y':\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_alterado = cv2.filter2D(gray, -1, k_sobel_y)\n",
    "    elif modo == 'zoom':\n",
    "        frame_alterado = frame[200:550,200:700]\n",
    "    elif modo == 'lines':\n",
    "        frame_alterado = cv2.filter2D(frame, -1, k2)\n",
    "    elif modo == 'relevo':\n",
    "        frame_alterado = cv2.filter2D(frame, -1, k1)\n",
    "    elif modo == 'filtro3':\n",
    "        frame_alterado = cv2.filter2D(frame, -1, k3)\n",
    "    elif modo == 'filtro4':\n",
    "        frame_alterado = cv2.filter2D(frame, -1, k4)\n",
    "    else:\n",
    "        frame_alterado = frame\n",
    "\n",
    "    return frame_alterado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "647ebdad-57f5-441b-a672-0c2cfb41ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_def(key, modo, tempo):\n",
    "    if key == ord('g'):\n",
    "        modo = 'gray'\n",
    "    elif key == ord('b'):\n",
    "        modo = 'binary'\n",
    "    elif key == ord('1'):\n",
    "        modo = 'color'\n",
    "    elif key == ord('l'):\n",
    "        modo = 'laplace'\n",
    "    elif key == ord('z'):\n",
    "        modo = 'zoom'\n",
    "    elif key == ord('p'):\n",
    "        modo = 'lines'\n",
    "    elif key == ord('r'):\n",
    "        modo = 'relevo'\n",
    "    elif key == ord('m'):\n",
    "        modo = 'filtro3'\n",
    "    elif key == ord('n'):\n",
    "        modo = 'filtro4'\n",
    "    elif key == ord('u'):\n",
    "        modo = 'blur'\n",
    "    elif key == ord('o'):\n",
    "        modo = 'emboss'\n",
    "    elif key == ord('h'):\n",
    "        modo = 'sharpen'\n",
    "    elif key == ord('x'):\n",
    "        modo = 'sobel-x'\n",
    "    elif key == ord('y'):\n",
    "        modo = 'sobel-y'\n",
    "    elif key == ord('e'):\n",
    "        modo = 'edges'\n",
    "    elif key == ord('+'):\n",
    "        tempo-=10\n",
    "        if tempo <=0:\n",
    "            tempo=1\n",
    "    elif key == ord('-'):\n",
    "        tempo+=10\n",
    "\n",
    "    return(modo, tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c301b3be-6bc2-4ef1-959c-362441e0fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_frames(cap, frame_inicial, frame_final, posicao, frame_alterado):\n",
    "    if frame_inicial is not None and frame_final is not None:\n",
    "        for i in range(frame_inicial, frame_final + 1):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame_to_save = cap.read()\n",
    "            if ret:\n",
    "                os.chdir(frames_folder)\n",
    "                cv2.imwrite(f'frame_{i}.png', frame_to_save)\n",
    "                os.chdir(path)                \n",
    "    else:\n",
    "        os.chdir(frames_folder)\n",
    "        cv2.imwrite(f'frame_{posicao}.png', frame_alterado)\n",
    "        os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "205e7c22-6208-4039-8a8f-e97bb9996cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def registrar_pontos_de_corte(cap, modo, tempo):\n",
    "    pontos_de_corte = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_alterado = modo_def(frame, modo)\n",
    "        cv2.imshow('Frame', frame_alterado)\n",
    "        key = cv2.waitKey(tempo) & 0xFF\n",
    "        if key == ord(' '):  # Barra de espaço\n",
    "            pontos_de_corte.append(cap.get(cv2.CAP_PROP_POS_MSEC) / 1000)  # Registra o tempo em segundos\n",
    "            print(f\"Ponto de corte registrado em {pontos_de_corte[-1]} segundos\")\n",
    "        elif key == ord('q'):\n",
    "            break\n",
    "    return pontos_de_corte\n",
    "\n",
    "def gerar_videos_intervalos(video, pontos_de_corte, modo, tempo):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    pontos_de_corte.sort()\n",
    "    pontos_de_corte.append(total_frames / fps)  # Adiciona o tempo final do vídeo\n",
    "    for i in range(len(pontos_de_corte) - 1):\n",
    "        inicio = pontos_de_corte[i]\n",
    "        fim = pontos_de_corte[i + 1]\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC, inicio * 1000)\n",
    "        frames_intervalo = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or cap.get(cv2.CAP_PROP_POS_MSEC) / 1000 >= fim:\n",
    "                break\n",
    "            frame_alterado = modo_def(frame, modo)\n",
    "            frames_intervalo.append(frame_alterado)\n",
    "        out = cv2.VideoWriter(f'video_{i+1}.mp4', fourcc, fps, (width, height))\n",
    "        for frame in frames_intervalo:\n",
    "            out.write(frame)\n",
    "        out.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def salvar_frames_intervalos(video, pontos_de_corte, modo, tempo):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    pontos_de_corte.sort()\n",
    "    pontos_de_corte.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))  # Adiciona o frame final do vídeo\n",
    "    for i in range(len(pontos_de_corte) - 1):\n",
    "        inicio = pontos_de_corte[i]\n",
    "        fim = pontos_de_corte[i + 1]\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, inicio)\n",
    "        frames_intervalo = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or cap.get(cv2.CAP_PROP_POS_FRAMES) >= fim:\n",
    "                break\n",
    "            frame_alterado = modo_def(frame, modo)\n",
    "            frames_intervalo.append(frame_alterado)\n",
    "        for j, frame in enumerate(frames_intervalo):\n",
    "            cv2.imwrite(f'frame_{i+1}_{j}.png', frame)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def escolher_salvar_frames_ou_video(video, pontos_de_corte, modo, tempo):\n",
    "    print(\"Escolha uma opção:\")\n",
    "    print(\"1. Salvar frames em separado\")\n",
    "    print(\"2. Converter em um novo vídeo\")\n",
    "    escolha = input(\"Digite a opção: \")\n",
    "    if escolha == \"1\":\n",
    "        salvar_frames_intervalos(video, pontos_de_corte, modo, tempo)\n",
    "    elif escolha == \"2\":\n",
    "        gerar_videos_intervalos(video, pontos_de_corte, modo, tempo)\n",
    "    else:\n",
    "        print(\"Opção inválida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c005e739-c0ba-4b5b-9f8a-a05b5fac2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def play_video_reverse(video, modo, tempo):\n",
    "    frames = []\n",
    "    cap_ = cv2.VideoCapture(video)\n",
    "    \n",
    "    # Ler todos os frames do vídeo e armazená-los\n",
    "    while True:\n",
    "        ret, frame = cap_.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_alterado = modo_def(frame, modo)\n",
    "        frames.append(frame_alterado)\n",
    "\n",
    "    # Verifica se há frames para reproduzir\n",
    "    if not frames:\n",
    "        print(\"Nenhum frame foi lido do vídeo.\")\n",
    "        cap_.release()  # Libera o objeto de captura antes de retornar\n",
    "        return\n",
    "\n",
    "    print(f\"Total de frames lidos: {len(frames)}\")  # Para verificar quantos frames foram lidos\n",
    "\n",
    "    # Loop para reproduzir os frames na ordem inversa até que 'q' seja pressionado\n",
    "    try:\n",
    "        while True:\n",
    "            index = len(frames) - 1  # Começa do último frame\n",
    "            while index >= 0:\n",
    "                cv2.imshow('Video Reverse', frames[index])\n",
    "                if cv2.waitKey(tempo) & 0xFF == ord('q'):\n",
    "                    cv2.destroyAllWindows()  # Fecha todas as janelas\n",
    "                    return  # Sai da função\n",
    "                index -= 1  # Decrementa o índice para ir para o frame anterior\n",
    "            \n",
    "            # Opcional: adicionar uma pausa entre as repetições\n",
    "            cv2.waitKey(1000)  # Pausa de 1 segundo entre repetições, se desejado\n",
    "    finally:\n",
    "        cap_.release()  # Garante que o objeto de captura seja liberado ao final\n",
    "\n",
    "# Exemplo de uso\n",
    "# video_path = 'seu_video.mp4'  # Substitua pelo caminho do seu vídeo\n",
    "# modo = ...  # Defina o modo desejado\n",
    "# tempo = 100  # Defina um tempo de espera em milissegundos\n",
    "# play_video_reverse(video_path, modo, tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beebbd95-9c6c-46b9-a543-800282d78484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "Escolha uma opção:\n",
      "1. Salvar frames em separado\n",
      "2. Converter em um novo vídeo\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Registrar pontos de corte\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     pontos_de_corte \u001b[38;5;241m=\u001b[39m registrar_pontos_de_corte(cap, modo, tempo)\n\u001b[1;32m---> 46\u001b[0m     \u001b[43mescolher_salvar_frames_ou_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpontos_de_corte\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m): \n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReproduzindo vídeo em reversa...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[16], line 68\u001b[0m, in \u001b[0;36mescolher_salvar_frames_ou_video\u001b[1;34m(video, pontos_de_corte, modo, tempo)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Salvar frames em separado\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. Converter em um novo vídeo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m escolha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDigite a opção: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m escolha \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     70\u001b[0m     salvar_frames_intervalos(video, pontos_de_corte, modo, tempo)\n",
      "File \u001b[1;32m~\\.conda\\envs\\teti2024\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\teti2024\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "modo = 'color'\n",
    "tempo = 10\n",
    "posicao = 0\n",
    "posicao_fixo = 0\n",
    "pause = 0\n",
    "frame_inicial = None\n",
    "frame_final = None\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(total_frames)\n",
    "\n",
    "if not os.path.exists(frames_folder):\n",
    "    os.makedirs(frames_folder)\n",
    "while True:\n",
    "    if not pause:\n",
    "        posicao += 1\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            posicao=0\n",
    "            continue\n",
    "\n",
    "    frame_alterado = modo_def(frame, modo)\n",
    "    if frame_alterado is not None:\n",
    "        cv2.imshow('Frame', frame_alterado)\n",
    "    else:\n",
    "        print(\"Frame alterado é None\")\n",
    "\n",
    "    key = cv2.waitKey(tempo) & 0xFF\n",
    "\n",
    "    modo, tempo = key_def(key, modo, tempo)\n",
    "    \n",
    "    if key == ord('p'):\n",
    "        pause = not pause\n",
    "    elif key == ord('s'):\n",
    "       salvar_frames(cap, frame_inicial, frame_final, posicao, frame_alterado)\n",
    "    elif key == ord('i'):\n",
    "        frame_inicial = posicao\n",
    "        print(f'Frame inicial marcado: {frame_inicial}')\n",
    "    elif key == ord('f'):\n",
    "        frame_final = posicao\n",
    "        print(f'Frame final marcado: {frame_final}')\n",
    "    elif key == ord('c'):  # Registrar pontos de corte\n",
    "        pontos_de_corte = registrar_pontos_de_corte(cap, modo, tempo)\n",
    "        escolher_salvar_frames_ou_video(video, pontos_de_corte, modo, tempo)\n",
    "    elif key == ord('='): \n",
    "        print(\"Reproduzindo vídeo em reversa...\")\n",
    "        play_video_reverse(video, modo, tempo)\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9faadf6-e4eb-4b7d-b4f4-f1fbeb481cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduzir_video_reverso():\n",
    "    global video_capture, canvas_video\n",
    "    frames = []\n",
    "    cap_ = video_capture\n",
    "    \n",
    "    # Ler todos os frames do vídeo e armazená-los\n",
    "    while True:\n",
    "        ret, frame = cap_.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Verifica se há frames para reproduzir\n",
    "    if not frames:\n",
    "        print(\"Nenhum frame foi lido do vídeo.\")\n",
    "        cap_.release()  # Libera o objeto de captura antes de retornar\n",
    "        return\n",
    "\n",
    "    print(f\"Total de frames lidos: {len(frames)}\")  # Para verificar quantos frames foram lidos\n",
    "\n",
    "    # Criar uma nova janela para reproduzir o vídeo reverso\n",
    "    janela_video_reverso = Toplevel()\n",
    "    janela_video_reverso.title(\"Reproduzir Vídeo Reverso\")\n",
    "\n",
    "    # Canvas para exibir os frames do vídeo\n",
    "    canvas_video = Canvas(janela_video_reverso, width=800, height=600, bg=\"black\")\n",
    "    canvas_video.pack()\n",
    "\n",
    "    # Função interna para reproduzir os frames em ordem reversa\n",
    "    def reproduzir_frames_reverso(index):\n",
    "        global frame_atual\n",
    "        if index < 0:\n",
    "            index = len(frames) - 1  # Reinicia a reprodução\n",
    "        frame = frames[index]\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_atual = ImageTk.PhotoImage(Image.fromarray(frame_rgb))\n",
    "    \n",
    "        # Atualiza o Canvas\n",
    "        canvas_video.create_image(0, 0, anchor=\"nw\", image=frame_atual)\n",
    "        canvas_video.img = frame_atual  # Previne garbage collection\n",
    "    \n",
    "        # Continuar reprodução\n",
    "        canvas_video.after(tempo_atual, reproduzir_frames_reverso, index - 1)\n",
    "    \n",
    "    # Função para iniciar a reprodução\n",
    "    def iniciar_reproducao():\n",
    "        reproduzir_frames_reverso(len(frames) - 1)\n",
    "\n",
    "    # Fechar a janela e liberar o vídeo ao fechar\n",
    "    def fechar_video_reverso():\n",
    "        if cap_ and cap_.isOpened():\n",
    "            cap_.release()\n",
    "        janela_video_reverso.destroy()\n",
    "\n",
    "    janela_video_reverso.protocol(\"WM_DELETE_WINDOW\", fechar_video_reverso)\n",
    "    \n",
    "    # Botões de controle\n",
    "    Button(janela_video_reverso, text=\"Reproduzir\", command=iniciar_reproducao).pack(side=\"left\", padx=5)\n",
    "    Button(janela_video_reverso, text=\"Capturar Quadro\", command=capturar_quadro).pack(side=\"left\", padx=5)\n",
    "    Button(janela_video_reverso, text=\"Fechar\", command=fechar_video_reverso).pack(side=\"right\", padx=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c970145e-802d-482a-ba7d-ebd0c8caf570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
