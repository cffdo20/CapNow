{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e248aeef-d173-4265-907c-d1bfa84bc73d",
   "metadata": {},
   "source": [
    "# image_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4af667-f034-4a2e-87e7-5ff19f63e85f",
   "metadata": {},
   "source": [
    "# Recursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dcbde61-9cfa-49da-bee6-444c3b00d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "import numpy as np\n",
    "from tkinter import filedialog, Toplevel, Canvas, Button, Frame\n",
    "from tkinter import Toplevel, Label, Button, Canvas, filedialog\n",
    "from PIL import Image, ImageTk\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e848cb-b154-494b-ae85-04114e9b6586",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f03ff86b-6537-4783-a875-aa953a5a2fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = np.array([[-1, -1, -1],[-1, 9, -1],[-1, -1, -1]])\n",
    "k2 = np.array([[1, 0, 0],[0, 0, 0],[0, 0, -1]])\n",
    "k3 = np.array([[0, 0, 0],[0, 1, 0],[0, 0, 0]])\n",
    "k4 = np.array([[0, -1, 0],[-1, 5, -1],[0, -1, 0]])\n",
    "k_blur = np.array([[1/9, 1/9, 1/9],[1/9, 1/9, 1/9],[1/9, 1/9, 1/9]], dtype=np.float32)\n",
    "k_sharpen = np.array([[0, -1, 0],[-1, 5, -1],[0, -1, 0]], dtype=np.float32)\n",
    "k_emboss = np.array([[2, 1, 0],[1, 0, -1],[0, -1, -2]], dtype=np.float32)\n",
    "k_laplace = np.array([[0,1,0],[1,-4,1],[0,1,0]], dtype = np.float32)\n",
    "k_sobel_x = np.array([[-1, 0, 1],[-2, 0, 2],[-1, 0, 1]], dtype=np.float32)\n",
    "k_sobel_y = np.array([[1, 2, 1],[0, 0, 0],[-1, -2, -1]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd9632-0e0a-41a3-b350-0ff8d90d350f",
   "metadata": {},
   "source": [
    "# Variáveis Globais de Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4893c2ab-49be-4c26-983e-3a92cc4acb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis globais para gerenciar o estado da imagem\n",
    "janela_principal = tk.Tk()\n",
    "imagem_original = None\n",
    "imagem_atual = None\n",
    "historico = []\n",
    "selection = None  # Coordenadas da área selecionada\n",
    "caminho = None\n",
    "independente = False\n",
    "canvas = None  # Definir canvas como variável global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1611e084-fced-4605-930b-4cfdfc6b6a39",
   "metadata": {},
   "source": [
    "# canvasController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1166f00a-21ab-4d66-9380-05ba5082c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções para manipular a seleção no canvas\n",
    "def iniciar_selecao(event):\n",
    "    global selection\n",
    "    selection = [event.x, event.y, event.x, event.y]  # Coordenadas iniciais\n",
    "\n",
    "def fazer_selecao(event):\n",
    "    global canvas, selection\n",
    "    if selection:\n",
    "        selection[2], selection[3] = event.x, event.y  # Atualizar coordenadas finais\n",
    "        canvas.delete(\"selection\")  # Remover seleção anterior\n",
    "        canvas.create_rectangle(\n",
    "            selection[0], selection[1], selection[2], selection[3], outline=\"red\", tags=\"selection\"\n",
    "        )\n",
    "\n",
    "def finalizar_selecao(event):\n",
    "    global selection\n",
    "    if selection:\n",
    "        selection[2], selection[3] = event.x, event.y  # Coordenadas finais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10213c4d-ac61-4dcf-a9e7-f28d6f8a597f",
   "metadata": {},
   "source": [
    "# Função de Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45a5755f-b96b-4848-9d39-e1612a5aa9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_zoom(acao):\n",
    "    global imagem_atual  # Declare que você está usando a variável global\n",
    "\n",
    "    # Verifica se imagem_atual é None ou não é uma imagem válida\n",
    "    if imagem_atual is None or not isinstance(imagem_atual, Image.Image):\n",
    "        print(\"Nenhuma imagem carregada ou imagem inválida.\")\n",
    "        return\n",
    "\n",
    "    # Agora você pode acessar a largura e altura\n",
    "    largura, altura = imagem_atual.size\n",
    "\n",
    "    if acao == \"mais\":\n",
    "        # Lógica para aumentar o zoom\n",
    "        nova_largura = int(largura * 1.1)  # Aumenta 10%\n",
    "        nova_altura = int(altura * 1.1)\n",
    "    elif acao == \"menos\":\n",
    "        # Lógica para diminuir o zoom\n",
    "        nova_largura = int(largura * 0.9)  # Diminui 10%\n",
    "        nova_altura = int(altura * 0.9)\n",
    "    else:\n",
    "        print(\"Ação de zoom inválida.\")\n",
    "        return\n",
    "\n",
    "    # Redimensiona a imagem\n",
    "    imagem_atual = imagem_atual.resize((nova_largura, nova_altura), Image.LANCZOS)\n",
    "\n",
    "    # Atualiza a visualização da imagem (supondo que você tenha um canvas ou algo similar)\n",
    "    atualizar_canvas(imagem_atual)\n",
    "\n",
    "def atualizar_canvas(imagem):\n",
    "    # Aqui você deve implementar a lógica para atualizar a visualização da imagem no seu canvas\n",
    "    imagem_tk = ImageTk.PhotoImage(imagem)\n",
    "    canvas.create_image(0, 0, anchor='nw', image=imagem_tk)\n",
    "    canvas.image = imagem_tk  # Mantém uma referência da imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8330f2-0ef4-4178-bbb5-8abaf18c5798",
   "metadata": {},
   "source": [
    "# Função para Abrir Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab337340-6c6c-4d3e-8ade-eb81dedff1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para abrir a imagem\n",
    "def abrir_imagem():\n",
    "    global imagem_original, imagem_atual, caminho, canvas\n",
    "    \n",
    "    # Abrir a caixa de diálogo para selecionar uma imagem\n",
    "    caminho_imagem = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png;*.bmp;*.gif\")])\n",
    "    \n",
    "    if caminho_imagem:\n",
    "        caminho = caminho_imagem\n",
    "        historico.clear()\n",
    "        imagem_original = Image.open(caminho_imagem)\n",
    "        imagem_atual = imagem_original\n",
    "        \n",
    "        # Converter a imagem para um formato que o Tkinter pode mostrar\n",
    "        imagem_tk = ImageTk.PhotoImage(imagem_atual)\n",
    "        \n",
    "        # Exibir a imagem no canvas\n",
    "        canvas.create_image(0, 0, anchor=\"nw\", image=imagem_tk)\n",
    "        canvas.image = imagem_tk  # Manter uma referência para a imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88551c85-20ce-4325-b79b-2a5d6c3ed879",
   "metadata": {},
   "source": [
    "# Funções para aplicar filtro em imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f2162a5-a8e9-4966-93c1-16f0f7299b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modo_def(modo):\n",
    "    global imagem_atual, imagem_original  # Certifique-se de que imagem_original está definida\n",
    "    if imagem_atual is None:\n",
    "        print(\"Nenhuma imagem carregada. Por favor, abra uma imagem primeiro.\")\n",
    "        return None\n",
    "\n",
    "    # Converter a imagem atual para um array NumPy para processamento com OpenCV\n",
    "    imagem_cv = cv2.cvtColor(np.array(imagem_atual), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if modo == 'gray':\n",
    "        return cv2.cvtColor(imagem_cv, cv2.COLOR_BGR2GRAY)\n",
    "    elif modo == 'binary':\n",
    "        gray = cv2.cvtColor(imagem_cv, cv2.COLOR_BGR2GRAY)\n",
    "        _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "        return binary\n",
    "    elif modo == 'blur':\n",
    "        imagem_rgb = cv2.cvtColor(imagem_cv, cv2.COLOR_BGR2RGB)\n",
    "        return cv2.GaussianBlur(imagem_rgb, (5, 5), 0)\n",
    "    elif modo == 'sharpen':\n",
    "        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "        return cv2.filter2D(imagem_cv, -1, kernel)\n",
    "    elif modo == 'emboss':\n",
    "        kernel = np.array([[0, -1, -1], [1, 0, -1], [1, 1, 0]])\n",
    "        return cv2.filter2D(imagem_cv, -1, kernel)\n",
    "    elif modo == 'laplace':\n",
    "        imagem_rgb = cv2.cvtColor(imagem_cv, cv2.COLOR_BGR2RGB)\n",
    "        laplacian = cv2.Laplacian(imagem_rgb, cv2.CV_64F)\n",
    "        return cv2.convertScaleAbs(laplacian)  # Converte para uint8\n",
    "    elif modo == 'sobel-x':\n",
    "        sobel_x = cv2.Sobel(imagem_cv, cv2.CV_64F, 1, 0, ksize=5)\n",
    "        return cv2.convertScaleAbs(sobel_x)  # Converte para uint8\n",
    "    elif modo == 'sobel-y':\n",
    "        sobel_y = cv2.Sobel(imagem_cv, cv2.CV_64F, 0, 1, ksize=5)\n",
    "        return cv2.convertScaleAbs(sobel_y)  # Converte para uint8\n",
    "    elif modo == 'edges':\n",
    "        return cv2.Canny(imagem_cv, 100, 200)\n",
    "    elif modo == 'original':\n",
    "        if 'imagem_original' in globals():\n",
    "            return np.array(imagem_original)  # Retorna a imagem original sem alterações\n",
    "        else:\n",
    "            print(\"Imagem original não está definida.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Modo não reconhecido.\")\n",
    "        return None\n",
    "\n",
    "def aplicar_filtro(modo):\n",
    "    global imagem_atual, independente\n",
    "    \n",
    "    if independente is True:\n",
    "        imagem_atual=Image.fromarray(modo_def('original'))\n",
    "    \n",
    "    imagem_alterada = modo_def(modo)  # Supondo que modo_def retorne uma imagem alterada\n",
    "\n",
    "\n",
    "    # Verifica se a imagem alterada é válida\n",
    "    if imagem_alterada is None:\n",
    "        print(\"A imagem alterada é None.\")\n",
    "        return\n",
    "    \n",
    "    # Verifica se a imagem alterada é um array NumPy\n",
    "    if not isinstance(imagem_alterada, np.ndarray):\n",
    "        print(\"A imagem alterada não é um array NumPy.\")\n",
    "        return\n",
    "\n",
    "    # Adiciona ao histórico\n",
    "    adicionar_historico()\n",
    "    # Atualiza a imagem_atual com a imagem alterada\n",
    "    imagem_atual = Image.fromarray(imagem_alterada)\n",
    "    atualizar_canvas(imagem_atual)\n",
    "    print(\"Filtro aplicado com sucesso.\")\n",
    "    \n",
    "def voltar_cor():\n",
    "    global imagem_atual, imagem_original\n",
    "    if imagem_original is not None:\n",
    "        imagem_atual = imagem_original\n",
    "        imagem_tk = ImageTk.PhotoImage(imagem_atual)\n",
    "        canvas.create_image(0, 0, anchor=\"nw\", image=imagem_tk)\n",
    "        canvas.image = imagem_tk  # Manter uma referência para a imagem\n",
    "\n",
    "def mostrar_original():\n",
    "    aplicar_filtro('original')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061437e5-0404-4879-97b3-7fc1cbf38070",
   "metadata": {},
   "source": [
    "# Funções para a Janela Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62da15c1-8982-428b-8075-519242a521b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tela principal\n",
    "def abrirJanelaPrincipal():\n",
    "    global canvas, selection, janela_principal # Tornar canvas acessível na função\n",
    "    \n",
    "    janela_principal.title(\"janela_principal\")\n",
    "    janela_principal.config(bg=\"whitesmoke\")\n",
    "    janela_principal.title(\"CapNow - Ferramenta de Manipulação de Imagem e Vídeo\")\n",
    "    janela_principal.geometry(\"800x800\")  # Tamanho inicial\n",
    "    janela_principal.minsize(600, 600)  # Tamanho mínimo da janela\n",
    "    janela_principal.resizable(True, True)\n",
    "\n",
    "    # Limpar histórico e seleção\n",
    "    selection = None\n",
    "\n",
    "    # Configurar o frame principal\n",
    "    frame = tk.Frame(janela_principal,\n",
    "                        borderwidth=0,\n",
    "                        relief=\"solid\",\n",
    "                        highlightbackground=\"lightblue\",\n",
    "                        highlightthickness=1)\n",
    "    \n",
    "    frameFiltros = tk.Frame(janela_principal,\n",
    "                        borderwidth=0,\n",
    "                        relief=\"solid\",\n",
    "                        highlightbackground=\"lightblue\",\n",
    "                        highlightthickness=1)\n",
    "    \n",
    "    frameCores = tk.Frame(janela_principal,\n",
    "                        borderwidth=0,\n",
    "                        relief=\"solid\",\n",
    "                        highlightbackground=\"lightblue\",\n",
    "                        highlightthickness=1)\n",
    "\n",
    "    frameArquivo = tk.Frame(janela_principal,\n",
    "                        borderwidth=0,\n",
    "                        relief=\"solid\",\n",
    "                        highlightbackground=\"lightblue\",\n",
    "                        highlightthickness=1)\n",
    "\n",
    "    frameControles = tk.Frame(janela_principal,\n",
    "                        borderwidth=0,\n",
    "                        relief=\"solid\",\n",
    "                        highlightbackground=\"lightblue\",\n",
    "                        highlightthickness=1)\n",
    "\n",
    "    # Configurando o label da página principal\n",
    "    label = tk.Label(janela_principal, text=\"CapNow\", font=(\"Lato\", 18, \"bold\"), fg=\"black\", bg=\"lightgray\")\n",
    "\n",
    "    # Canvas para a imagem\n",
    "    canvas = Canvas(frame, width=500, height=300, bg=\"gray\")\n",
    "        \n",
    "\n",
    "    # Ativar seleção no canvas\n",
    "    canvas.bind(\"<ButtonPress-1>\", iniciar_selecao)\n",
    "    canvas.bind(\"<B1-Motion>\", fazer_selecao)\n",
    "    canvas.bind(\"<ButtonRelease-1>\", finalizar_selecao)\n",
    "\n",
    "    # Adicionando nas posições desejadas\n",
    "    # Row 0\n",
    "    label.grid(row=0, column=0, columnspan=10, padx=10, pady=5, sticky=\"ew\")\n",
    "    frameArquivo.grid(row=1, column=0, padx=10, pady=10)\n",
    "    frame.grid(row=2, column=0, padx=10, pady=10, sticky=\"nsew\")\n",
    "    frameFiltros.grid(row=4, column=0, padx=10, pady=10, sticky=\"nsew\")\n",
    "    frameCores.grid(row=2, column=1, padx=10, pady=10)\n",
    "    frameControles.grid(row=3, column=2, padx=10, pady=10)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Row 1\n",
    "    Button(frameArquivo, text=\"Abrir Imagem\", command=abrir_imagem).grid(row=0, column=0, padx=10, pady=5, sticky=\"ew\")\n",
    "    canvas.grid(row=1, column=1, columnspan=10, rowspan=10, sticky=\"nsew\", pady=10)\n",
    "\n",
    "    # Row 2\n",
    "    Button(frameArquivo, text=\"Abrir vídeo\", command=abrir_video).grid(row=0, column=1, padx=10, pady=5, sticky=\"ew\")\n",
    "\n",
    "\n",
    "\n",
    "    ## Menu de Filtros de Convolução\n",
    "   # Adicionando botões de filtros\n",
    "    adicionar_botoes_filtros(frameFiltros)\n",
    "\n",
    "    ## Menu de Modo de Cor\n",
    "    # Row 11\n",
    "    modeCorLabel = tk.Label(frameCores, text=\"Modo de Cor\")\n",
    "    modeCorLabel.grid(row=0, column=0, padx=5,pady=10)\n",
    "    # Row 12\n",
    "    Button(frameCores, text=\"Cinza\", command=lambda: aplicar_filtro('gray')).grid(row=1, column=0, padx=10, pady=5, sticky=\"ew\")\n",
    "    # Row 13\n",
    "    Button(frameCores, text=\"Binário\", command=lambda: aplicar_filtro('binary')).grid(row=2, column=0, padx=10, pady=5, sticky=\"ew\")\n",
    "    # Row 14\n",
    "    Button(frameCores, text=\"Cor\", command=voltar_cor).grid(row=3, column=0, padx=10, pady=5, sticky=\"ew\")\n",
    "\n",
    "    \n",
    "    ## Controles Gerais\n",
    "    # Row 11\n",
    "    #menuGeralLabel = tk.Label(frame, text=\"Controles Gerais\")\n",
    "    #menuGeralLabel.grid(row=11, column=1, padx=5,pady=10)\n",
    "    \n",
    "    # Row 12\n",
    "    Button(frameControles, text=\"Desfazer\", command=desfazer).grid(row=0, column=0, padx=10, pady=5, sticky=\"ew\")\n",
    "    # Row 13\n",
    "    Button(frameControles, text=\"Original\", command=mostrar_original).grid(row=0, column=1, padx=10, pady=5, sticky=\"ew\")\n",
    "    # Row 14\n",
    "    Button(frameControles, text=\"Salvar Imagem\", command=salvar_imagem).grid(row=0, column=2, padx=10, pady=5, sticky=\"ew\")\n",
    "    Button(frameControles, text=\"Salvar Imagens no Histórico\", command=salvar_imagens_historico).grid(row=1, column=2, padx=10, pady=5, sticky=\"ew\")\n",
    "    Button(frameControles, text=\"Ativar/Desativar Filtro independente\", command=filtro_independente).grid(row=1, column=1, padx=10, pady=5, sticky=\"ew\")\n",
    "\n",
    "    # Row 15\n",
    "    #Button(frame, text=\"Fechar\").grid(row=15, column=1, padx=10, pady=5, stick=\"ew\")\n",
    "\n",
    "    ## Opções do Quadro\n",
    "    # Row 11\n",
    "    menuQuadroLabel = tk.Label(frame, text=\"Opções Quadro\")\n",
    "    menuQuadroLabel.grid(row=11, column=2, padx=5,pady=10)\n",
    "    # Row 12\n",
    "    Button(frame, text=\"Zoom na Seleção\", command=aplicar_zoom_selecao).grid(row=12, column=2, padx=10, pady=5, sticky=\"ew\")\n",
    "    # Row 13\n",
    "    Button(frame, text=\"Zoom +\", command=lambda: aplicar_zoom(\"mais\")).grid(row=13, column=2, padx=10, pady=5, sticky=\"ew\")\n",
    "    # Row 14\n",
    "    Button(frame, text=\"Zoom -\", command=lambda: aplicar_zoom(\"menos\")).grid(row=14, column=2, padx=10, pady=5, sticky=\"ew\")\n",
    "\n",
    "     ## Opções de Vídeo\n",
    "    # Row 11\n",
    "    menuVideoLabel = tk.Label(frame, text=\"Opções Vídeo\")\n",
    "    menuVideoLabel.grid(row=11, column=3, columnspan=2, padx=5,pady=10)\n",
    "    # Row 12\n",
    "    Button(frameControles, text=\"Reproduzir\").grid(row=0, column=3, padx=10, pady=5, stick=\"ew\")\n",
    "    Button(frameControles, text=\"Reverter\").grid(row=0, column=4, padx=5, pady=5, stick=\"ew\")\n",
    "    # Row 13\n",
    "    Button(frame, text=\"Acelerar\").grid(row=13, column=3, padx=10, pady=5, stick=\"ew\")\n",
    "    Button(frame, text=\"Desacelerar\").grid(row=13, column=4, padx=5, pady=5, stick=\"ew\")\n",
    "    # Row 14\n",
    "    Button(frame, text=\"Cortar\").grid(row=14, column=3, padx=10, pady=5, stick=\"ew\")\n",
    "    Button(frame, text=\"Salvar Frame\").grid(row=14, column=4, padx=5, pady=5, stick=\"ew\")\n",
    "\n",
    "    # Inicia a interface\n",
    "    return janela_principal\n",
    "\n",
    "def adicionar_botoes_filtros(frameFiltros):\n",
    "    # Filtros de Convolução\n",
    "    Button(frameFiltros, text=\"Blur\", command=lambda: aplicar_filtro('blur')).grid(row=5, column=0, padx=10, pady=5, sticky=\"ew\")\n",
    "    Button(frameFiltros, text=\"Sharpen\", command=lambda: aplicar_filtro('sharpen')).grid(row=6, column=0, padx=10, pady=5, sticky=\"ew\")\n",
    "    Button(frameFiltros, text=\"Emboss\", command=lambda: aplicar_filtro('emboss')).grid(row=7, column=0, padx=10, pady=5, sticky=\"ew\")\n",
    "    Button(frameFiltros, text=\"Laplacian\", command=lambda: aplicar_filtro('laplace')).grid(row=8, column=0, padx=10, pady=5, sticky=\"ew\")\n",
    "    Button(frameFiltros, text=\"Sobel X\", command=lambda: aplicar_filtro('sobel-x')).grid(row=9, column=0, padx=10, pady=5, sticky=\"ew\")\n",
    "    Button(frameFiltros, text=\"Sobel Y\", command=lambda: aplicar_filtro('sobel-y')).grid(row=10, column=0, padx=10, pady=5, sticky=\"ew\")\n",
    "    Button(frameFiltros, text=\"Canny\", command=lambda: aplicar_filtro('edges')).grid(row=11, column=0, padx=10, pady=5, sticky=\"ew\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757f06cb-009a-49b5-9495-2294e3c1a27e",
   "metadata": {},
   "source": [
    "# Funções de Manipulação de Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a477272e-3eb9-42fc-b7f1-e47ebfa4b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_independente():\n",
    "    global imagem_atual, imagem_original, independente\n",
    "    if independente is False:\n",
    "        print(\"Filtro Independente Ativado\")\n",
    "        independente = not independente\n",
    "        adicionar_historico()\n",
    "        mostrar_original()\n",
    "    else:\n",
    "        print(\"Filtro Independente Desativado\")\n",
    "        independente = not independente\n",
    "        desfazer()\n",
    "        \n",
    "# Função para adicionar histórico\n",
    "def adicionar_historico():\n",
    "    global imagem_atual, historico, independente\n",
    "    # Verifica se imagem_atual é None\n",
    "    if imagem_atual is None:\n",
    "        print(\"Nenhuma imagem para adicionar ao histórico.\")\n",
    "        return\n",
    "    \n",
    "    # Adiciona a imagem atual ao histórico\n",
    "    if independente is True:\n",
    "        print(\"Filtro Independente ativado, impossível salvar no histórico.\")\n",
    "    else:\n",
    "        historico.append(imagem_atual.copy())  # Usar copy() para evitar referências\n",
    "        print(\"Imagem adicionada ao histórico.\")\n",
    "    \n",
    "\n",
    "# Função para desfazer\n",
    "def desfazer():\n",
    "    global imagem_atual, historico, canvas, independente\n",
    "\n",
    "    if not historico:\n",
    "        print(\"Nenhuma ação para desfazer.\")\n",
    "        return\n",
    "    elif independente is True:\n",
    "        print(\"Filtro Independente Ativado. Imposssível realizar operação.\")\n",
    "    imagem_atual = historico.pop()  # Remove a última imagem do histórico\n",
    "    atualizar_canvas(imagem_atual)\n",
    "\n",
    "# Função para aplicar zoom na área selecionada, mantendo proporções\n",
    "def aplicar_zoom_selecao():\n",
    "    global imagem_atual, selection\n",
    "    if imagem_atual is None:\n",
    "        print(\"Nenhuma imagem carregada para aplicar zoom.\")\n",
    "        return\n",
    "\n",
    "    if not selection:\n",
    "        print(\"Nenhuma área selecionada para aplicar zoom.\")\n",
    "        return\n",
    "        \n",
    "    \n",
    "    adicionar_historico()\n",
    "    x1, y1, x2, y2 = selection\n",
    "\n",
    "    # Certificar-se de que as coordenadas estão dentro dos limites\n",
    "    largura, altura = imagem_atual.size\n",
    "    x1, x2 = max(0, min(x1, x2)), min(largura, max(x1, x2))\n",
    "    y1, y2 = max(0, min(y1, y2)), min(altura, max(y1, y2))\n",
    "\n",
    "    # Recortar a área selecionada\n",
    "    area_selecionada = imagem_atual.crop((x1, y1, x2, y2))\n",
    "\n",
    "    # Calcular nova dimensão preservando proporção\n",
    "    largura_selecao, altura_selecao = area_selecionada.size\n",
    "    fator_zoom = 2  # Fator de zoom\n",
    "    nova_largura = int(largura_selecao * fator_zoom)\n",
    "    nova_altura = int(altura_selecao * fator_zoom)\n",
    "\n",
    "    area_ampliada = area_selecionada.resize((nova_largura, nova_altura), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Centralizar no Canvas mantendo proporção\n",
    "    canvas_largura, canvas_altura = 500, 500\n",
    "    proporcao_area = nova_largura / nova_altura\n",
    "    proporcao_canvas = canvas_largura / canvas_altura\n",
    "\n",
    "    if proporcao_area > proporcao_canvas:\n",
    "        # Ajustar pela largura\n",
    "        largura_final = canvas_largura\n",
    "        altura_final = int(largura_final / proporcao_area)\n",
    "    else:\n",
    "        # Ajustar pela altura\n",
    "        altura_final = canvas_altura\n",
    "        largura_final = int(altura_final * proporcao_area)\n",
    "\n",
    "    area_final = area_ampliada.resize((largura_final, altura_final), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Criar uma nova imagem com fundo cinza e centralizar a área ampliada\n",
    "    imagem_zoom = Image.new(\"RGB\", (canvas_largura, canvas_altura), \"gray\")\n",
    "    offset_x = (canvas_largura - largura_final) // 2\n",
    "    offset_y = (canvas_altura - altura_final) // 2\n",
    "    imagem_zoom.paste(area_final, (offset_x, offset_y))\n",
    "\n",
    "    imagem_atual = imagem_zoom\n",
    "    exibir_imagem_no_canvas()\n",
    "\n",
    "def salvar_imagens_historico():\n",
    "    global historico\n",
    "    if not historico:\n",
    "        print(\"Nenhuma imagem para salvar.\")\n",
    "        return\n",
    "    \n",
    "    # Solicita ao usuário um diretório para salvar as imagens\n",
    "    diretorio = filedialog.askdirectory()\n",
    "    if not diretorio:\n",
    "        print(\"Nenhum diretório selecionado.\")\n",
    "        return\n",
    "\n",
    "    # Salva cada imagem do histórico em um arquivo separado\n",
    "    for i, h in enumerate(historico):\n",
    "        # Cria um nome de arquivo único para cada imagem\n",
    "        nome_arquivo = os.path.join(diretorio, f\"imagem_historico_{i + 1}.png\")\n",
    "        h.save(nome_arquivo)\n",
    "        print(f\"Imagem salva em: {nome_arquivo}\")\n",
    "        \n",
    "def salvar_imagem():\n",
    "    global imagem_atual\n",
    "    if imagem_atual is None:\n",
    "        print(\"Nenhuma imagem carregada para salvar.\")\n",
    "        return\n",
    "\n",
    "    caminho = filedialog.asksaveasfilename(defaultextension=\".png\", filetypes=[(\"PNG\", \"*.png\"), (\"JPEG\", \"*.jpg\")])\n",
    "    if caminho:\n",
    "        imagem_atual.save(caminho)\n",
    "        print(f\"Imagem salva em: {caminho}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf57fa-165c-4ddd-a69d-02b6065b4d44",
   "metadata": {},
   "source": [
    "# Variáveis Globais de Vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8d503b5-70d2-43f7-b26f-775d082c1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis globais para controle de vídeo\n",
    "video_capture = None\n",
    "video_capture_webcam = None\n",
    "canvas_video = None\n",
    "frame_atual = None\n",
    "tempo_atual = 10  # Tempo em milissegundos entre os quadros\n",
    "filtro_atual = None\n",
    "paused = False\n",
    "tempos_corte = [0]  # Lista para armazenar os tempos de corte\n",
    "tempo_total = 0  # Tempo total do vídeo\n",
    "video_path = \"\"# Caminho do vídeo\n",
    "cont_frames = 0 #contador de frames\n",
    "cont_frames_webcam = 0 #contador de frames da webcam\n",
    "parador = False\n",
    "frames_webcam=[]\n",
    "webcam_used = False\n",
    "janelas_abertas = []\n",
    "frames_reverso = []\n",
    "video_status = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c236454-0ebc-4ed0-a3ec-830efb025c93",
   "metadata": {},
   "source": [
    "# Funções para Criar Janela de Vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8f6f95-7bdd-46be-8dd5-6eae2d1a1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_janela_video(title):\n",
    "    global canvas_video, video_capture, frame_video\n",
    "\n",
    "    # Criar janela de vídeo\n",
    "    janela_video = Toplevel()\n",
    "    janela_video.title(title)\n",
    "\n",
    "    # Criar um Frame para o Canvas e a barra de rolagem\n",
    "    frame_canvas = Frame(janela_video)\n",
    "    frame_canvas.grid(row=0, column=0)\n",
    "\n",
    "    # Criar Canvas com as dimensões do vídeo\n",
    "    canvas_video = Canvas(frame_canvas, width=700, height=600, bg=\"black\")\n",
    "    canvas_video.grid(row=0, column=0, sticky=\"nsew\")\n",
    "\n",
    "    # Criar barra de rolagem\n",
    "    scrollbar = Scrollbar(frame_canvas, orient=VERTICAL, command=canvas_video.yview)\n",
    "    scrollbar.grid(row=0, column=1, sticky='ns')\n",
    "\n",
    "    # Configurar o Canvas para usar a barra de rolagem\n",
    "    canvas_video.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "    # Criar um Frame dentro do Canvas\n",
    "    frame_video = Frame(canvas_video)\n",
    "    canvas_video.create_window((0, 0), window=frame_video, anchor='nw')\n",
    "\n",
    "    # Configurar o Frame para expandir\n",
    "    frame_video.bind(\"<Configure>\", lambda e: canvas_video.configure(scrollregion=canvas_video.bbox(\"all\")))\n",
    "\n",
    "    # Criar um Frame para os botões\n",
    "    frame_botoes = Frame(janela_video)\n",
    "    frame_botoes.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "    # Adicionar botões de controle de reprodução\n",
    "    Button(frame_botoes, text=\"Reproduzir\", command=reproduzir_video).grid(row=0, column=0, padx=5, pady=5)\n",
    "    Button(frame_botoes, text=\"Pausar\", command=pause_video).grid(row=0, column=1, padx=5, pady=5)\n",
    "    Button(frame_botoes, text=\"Reproduzir Vídeo em Reverso\", command=reproduzir_video_reverso_if).grid(row=0, column=2, padx=5, pady=5)\n",
    "    Button(frame_botoes, text=\"Capturar Quadro\", command=capturar_quadro).grid(row=0, column=3, padx=5, pady=5)\n",
    "    Button(frame_botoes, text=\"Fechar\", command=lambda: fechar_video(janela_video)).grid(row=0, column=4, padx=5, pady=5)\n",
    "    Button(frame_botoes, text=\"Registrar Tempo\", command=registrar_tempo).grid(row=5, column=0, padx=5, pady=5)\n",
    "    Button(frame_botoes, text=\"Gerar Vídeos\", command=gerar_videos).grid(row=5, column=1, padx=5, pady=5)\n",
    "    Button(frame_botoes, text=\"Salvar Frames\", command=salvar_frames).grid(row=5, column=2, padx=5, pady=5)\n",
    "\n",
    "    # Botão para usar a webcam\n",
    "    Button(frame_botoes, text=\"Usar Webcam\", command=usar_webcam).grid(row=1, column=0, columnspan=5, padx=5, pady=5)\n",
    "\n",
    "    # Adicionar botões de filtro na linha 2\n",
    "    adicionar_botoes_filtros_video(frame_botoes)\n",
    "\n",
    "    # Botões para aumentar e diminuir o tempo na linha 3\n",
    "    Button(frame_botoes, text=\"Aumentar Tempo\", command=aumentar_tempo).grid(row=4, column=0, padx=5, pady=5)\n",
    "    Button(frame_botoes, text=\"Diminuir Tempo\", command=diminuir_tempo).grid(row=4, column=1, padx=5, pady=5)\n",
    "\n",
    "def adicionar_botoes_filtros_video(frame):\n",
    "    # Adiciona botões para aplicar filtros usando grid\n",
    "    Button(frame, text=\"Cinza\", command=lambda: mudar_filtro('gray')).grid(row=2, column=0, padx=5, pady=5)\n",
    "    Button(frame, text=\"Binário\", command=lambda: mudar_filtro('binary')).grid(row=2, column=1, padx=5, pady=5)\n",
    "    Button(frame, text=\"Blur\", command=lambda: mudar_filtro('blur')).grid(row=2, column=2, padx=5, pady=5)\n",
    "    Button(frame, text=\"Sharpen\", command=lambda: mudar_filtro('sharpen')).grid(row=2, column=3, padx=5, pady=5)\n",
    "    Button(frame, text=\"Emboss\", command=lambda: mudar_filtro('emboss')).grid(row=3, column=0, padx=5, pady=5)\n",
    "    Button(frame, text=\"Laplacian\", command=lambda: mudar_filtro('laplace')).grid(row=3, column=1, padx=5, pady=5)\n",
    "    Button(frame, text=\"Sobel X\", command=lambda: mudar_filtro('sobel-x')).grid(row=3, column=2, padx=5, pady=5)\n",
    "    Button(frame, text=\"Sobel Y\", command=lambda: mudar_filtro('sobel-y')).grid(row=3, column=3, padx=5, pady=5)\n",
    "    Button(frame, text=\"Canny\", command=lambda: mudar_filtro('edges')).grid(row=4, column=2, padx=5, pady=5)\n",
    "    Button(frame, text=\"Sem Filtro\", command=lambda: mudar_filtro('original')).grid(row=4, column=3, padx=5, pady=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6673b0-1ce0-4a1c-917c-03ee3f389f56",
   "metadata": {},
   "source": [
    "# Funções para Reprodução de Vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12186a47-da1c-4fe5-938f-49af980b99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduzir_video():\n",
    "    global video_capture, canvas_video, frame_atual, filtro_atual, paused, tempo_total, cont_frames, video_path, video_status\n",
    "    if paused: # Se estiver pausado, não faz nada\n",
    "        return\n",
    "    \n",
    "    if not video_capture or not video_capture.isOpened():\n",
    "        print(\"Nenhum vídeo carregado para reprodução.\")\n",
    "        abrir_video()\n",
    "        return\n",
    "\n",
    "    if video_status is True:\n",
    "        video_status = not video_status\n",
    "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        return reproduzir_video()\n",
    "        \n",
    "    # Ler próximo quadro do vídeo\n",
    "    ret, frame = video_capture.read()\n",
    "    cont_frames+=1\n",
    "    if not ret:\n",
    "        video_status = not video_status\n",
    "        print(\"Fim do vídeo ou erro ao ler o quadro. Reiniciando o vídeo.\")\n",
    "        return\n",
    "        #video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reinicia o vídeo\n",
    "        #return reproduzir_video()  # Tenta reproduzir novamente\n",
    "    if not paused:\n",
    "        # Aplicar filtro se um filtro atual estiver definido\n",
    "        frame_processado=None\n",
    "        if filtro_atual:\n",
    "            frame = modo_def_video(frame, filtro_atual)\n",
    "        frame_processado = normalizar_frame(frame)\n",
    "        frame_processado = cv2.cvtColor(frame_processado, cv2.COLOR_BGR2RGB)\n",
    "        frame_atual = ImageTk.PhotoImage(Image.fromarray(frame_processado))\n",
    "    \n",
    "        # Atualizar o Canvas\n",
    "        canvas_video.create_image(0, 0, anchor=\"nw\", image=frame_atual)\n",
    "        canvas_video.img = frame_atual  # Previne garbage collection\n",
    "    \n",
    "        # Continuar reprodução\n",
    "        canvas_video.after(tempo_atual, reproduzir_video)\n",
    "\n",
    "def reproduzir_video_webcam():\n",
    "    global video_capture_webcam, canvas_video, frame_atual, filtro_atual, paused, tempo_total, cont_frames_webcam, frames_webcam, video_status\n",
    "    if paused: # Se estiver pausado, não faz nada\n",
    "        tempo_total=cont_frames_webcam;\n",
    "        return\n",
    "    if not video_capture_webcam or not video_capture_webcam.isOpened():\n",
    "        print(\"Nenhum vídeo carregado para reprodução.\")\n",
    "        return\n",
    "\n",
    "  \n",
    "    # Ler próximo quadro do vídeo\n",
    "    ret, frame = video_capture_webcam.read()\n",
    "    cont_frames_webcam+=1\n",
    "    if not ret:\n",
    "        print(\"Fim do vídeo ou erro ao ler o quadro. Reiniciando o vídeo.\")\n",
    "        video_capture_webcam.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reinicia o vídeo\n",
    "        return reproduzir_video_webcam()  # Tenta reproduzir novamente\n",
    "    if not paused:\n",
    "        frame_processado=None\n",
    "        # Aplicar filtro se um filtro atual estiver definido\n",
    "        if filtro_atual:\n",
    "            frame = modo_def_video(frame, filtro_atual)\n",
    "        frame_processado = normalizar_frame(frame)\n",
    "        frame_processado = cv2.cvtColor(frame_processado, cv2.COLOR_BGR2RGB)\n",
    "        frame_atual = ImageTk.PhotoImage(Image.fromarray(frame_processado))\n",
    "    \n",
    "        # Atualizar o Canvas\n",
    "        canvas_video.create_image(0, 0, anchor=\"nw\", image=frame_atual)\n",
    "        canvas_video.img = frame_atual  # Previne garbage collection\n",
    "    \n",
    "        # Continuar reprodução\n",
    "        canvas_video.after(tempo_atual, reproduzir_video_webcam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e9e465-c7f5-49e4-8d7c-8003bd393ac6",
   "metadata": {},
   "source": [
    "# Funções de seleção de Vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa90265-27fb-4320-90e0-cde00c6f7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abrir_video():\n",
    "    global video_capture, canvas_video, tempo_total, video_path, video_capture_reverso\n",
    "\n",
    "    # Seleção de arquivo de vídeo\n",
    "    caminho = filedialog.askopenfilename(filetypes=[(\"Vídeos\", \"*.mp4;*.avi;*.mov\")])\n",
    "    if not caminho:\n",
    "        return\n",
    "\n",
    "    # Abrir vídeo com OpenCV\n",
    "    video_capture = cv2.VideoCapture(caminho)\n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Erro ao abrir o vídeo.\")\n",
    "        return\n",
    "    # Armazenar o caminho do vídeo\n",
    "    video_path = caminho\n",
    "    print(\"video_path\"+video_path)\n",
    "\n",
    "    # Calcular o tempo total do vídeo\n",
    "    tempo_total = contar_frames()\n",
    "    print(f\"Duração total do vídeo: {tempo_total} frames\")\n",
    "    # Criar janela de vídeo\n",
    "    janelas_abertas.append(\"Vizualizar Video\")\n",
    "    criar_janela_video(\"Vizualizar Video\")\n",
    "def usar_webcam():\n",
    "    global video_capture_webcam, webcam_used\n",
    "    webcam_used=True\n",
    "    video_capture_webcam = cv2.VideoCapture(0)  # 0 é o índice da webcam padrão\n",
    "    if not video_capture_webcam.isOpened():\n",
    "        print(\"Erro ao acessar a webcam.\")\n",
    "        return\n",
    "    # Criar janela de vídeo\n",
    "    janelas_abertas.append(\"Webcam\")\n",
    "    fechar_janela_por_titulo(\"Vizualizar Video\")\n",
    "    criar_janela_video(\"Webcam\")\n",
    "    # Inicia a reprodução da webcam\n",
    "    reproduzir_video_webcam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a9c5b-0749-45fc-8f75-9ac08af0d04b",
   "metadata": {},
   "source": [
    "# Funções para manipulação de Vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ea1d4fc-7f76-450b-a87f-d8c87590a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_frame(frame):\n",
    "    if frame is None:\n",
    "        return None\n",
    "    if len(frame.shape) == 2:  # Se for uma imagem em escala de cinza\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)  # Converte para BGR\n",
    "    return frame  # Retorna o frame como está se já for BGR\n",
    "def aumentar_tempo():\n",
    "    global tempo_atual\n",
    "    tempo_atual += 10  # Aumenta o tempo em 50 ms\n",
    "    print(f\"Tempo atual aumentado: {tempo_atual} ms\")\n",
    "\n",
    "def diminuir_tempo():\n",
    "    global tempo_atual\n",
    "    tempo_atual = max(0, tempo_atual - 10)  # Diminui o tempo em 50 ms, não permitindo valores negativos\n",
    "    print(f\"Tempo atual diminuído: {tempo_atual} ms\")\n",
    "def pause_video():\n",
    "    global paused\n",
    "    paused = not paused  # Alterna o estado de pausa\n",
    "    if paused:\n",
    "        print(\"Vídeo pausado.\")\n",
    "    else:\n",
    "        print(\"Vídeo retomado.\")\n",
    "        reproduzir_video()\n",
    "def capturar_quadro():\n",
    "    global frame_atual\n",
    "\n",
    "    if not frame_atual:\n",
    "        print(\"Nenhum quadro disponível para capturar.\")\n",
    "        return\n",
    "\n",
    "    # Salvar o quadro atual como imagem\n",
    "    frame_atual._PhotoImage__photo.write(\"quadro_capturado.png\", format=\"png\")\n",
    "    print(\"Quadro capturado e salvo como 'quadro_capturado.png'.\")\n",
    "\n",
    "def fechar_video(janela):\n",
    "    global video_capture\n",
    "    if video_capture_webcam  and video_capture_webcam.isOpened():\n",
    "        video_capture_webcam.release()\n",
    "        fechar_janela_por_titulo(\"Webcam\")\n",
    "    elif video_capture and video_capture.isOpened():\n",
    "        video_capture.release()\n",
    "        fechar_janela_por_titulo(\"Vizualizar Video\")\n",
    "        fechar_janela_por_titulo(\"Video Reverso\")\n",
    "\n",
    "def fechar_janela(titulo, janela):\n",
    "    # Remove o título da janela da lista e fecha a janela\n",
    "    if titulo in janelas_abertas:\n",
    "        janelas_abertas.remove(titulo)\n",
    "    janela.destroy()\n",
    "\n",
    "def fechar_janela_por_titulo(titulo):\n",
    "    # Fecha a janela com o título especificado\n",
    "    global janela_principal\n",
    "    for janela in janela_principal.winfo_children():\n",
    "        if isinstance(janela, tk.Toplevel) and janela.title() == titulo:\n",
    "            fechar_janela(titulo, janela)\n",
    "            break\n",
    "\n",
    "def contar_frames():\n",
    "    global video_path\n",
    "    cap_cont = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap_cont.isOpened():\n",
    "        print(\"Erro: O vídeo não está aberto.\")\n",
    "        return 0\n",
    "\n",
    "    total_frames = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap_cont.read()\n",
    "        if not ret:\n",
    "            break  # Sai do loop se não houver mais frames\n",
    "\n",
    "        total_frames += 1\n",
    "\n",
    "    \n",
    "    cap_cont.release()\n",
    "\n",
    "    return total_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e816596-a42d-4994-996a-242941165c3d",
   "metadata": {},
   "source": [
    "# Funções para aplicar filtros em Vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c52c3e2-4a11-4391-9056-89e2c81740ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modo_def_video(frame, modo):\n",
    "    if frame is None:\n",
    "        print(\"Nenhum quadro carregado. Por favor, abra um vídeo primeiro.\")\n",
    "        return None\n",
    "\n",
    "    if modo == 'gray':\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    elif modo == 'binary':\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "        return binary\n",
    "    elif modo == 'blur':\n",
    "        return cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    elif modo == 'sharpen':\n",
    "        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "        return cv2.filter2D(frame, -1, kernel)\n",
    "    elif modo == 'emboss':\n",
    "        kernel = np.array([[0, -1, -1], [1, 0, -1], [1, 1, 0]])\n",
    "        return cv2.filter2D(frame, -1, kernel)\n",
    "    elif modo == 'laplace':\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Converte para escala de cinza\n",
    "        laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "        return cv2.convertScaleAbs(laplacian)  # Converte para uint8\n",
    "    elif modo == 'sobel-x':\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Converte para escala de cinza\n",
    "        sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n",
    "        return cv2.convertScaleAbs(sobel_x)  # Converte para uint8\n",
    "    elif modo == 'sobel-y':\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Converte para escala de cinza\n",
    "        sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n",
    "        return cv2.convertScaleAbs(sobel_y)  # Converte para uint8\n",
    "    elif modo == 'edges':\n",
    "        return cv2.Canny(frame, 100, 200)\n",
    "    elif modo == 'original':\n",
    "        return frame\n",
    "    else:\n",
    "        print(\"Modo não reconhecido.\")\n",
    "        return None\n",
    "\n",
    "def mudar_filtro(novo_filtro):\n",
    "    global filtro_atual\n",
    "    filtro_atual = novo_filtro  # Atualiza o filtro atual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed65303a-4522-4e9e-836f-6d8066fa0da2",
   "metadata": {},
   "source": [
    "# Funções para reverter vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00554913-35a7-43bc-896d-71ad30d4538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduzir_video_reverso_if():\n",
    "    global frames_reverso\n",
    "    if not frames_reverso:\n",
    "        reproduzir_video_reverso() \n",
    "    else:\n",
    "        iniciar_reproducao()\n",
    "def reproduzir_video_reverso():\n",
    "    global video_capture, canvas_video, paused, frames_reverso\n",
    "    if paused:\n",
    "        return\n",
    "    cap_ = video_capture\n",
    "    \n",
    "    # Ler todos os frames do vídeo e armazená-los\n",
    "    while True:\n",
    "        ret, frame = cap_.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames_reverso.append(frame)\n",
    "\n",
    "    # Verifica se há frames para reproduzir\n",
    "    if not frames_reverso:\n",
    "        print(\"Nenhum frame foi lido do vídeo.\")\n",
    "        cap_.release()  # Libera o objeto de captura antes de retornar\n",
    "        return\n",
    "\n",
    "    print(f\"Total de frames lidos: {len(frames_reverso)}\")  # Para verificar quantos frames foram lidos\n",
    "\n",
    "    janelas_abertas.append(\"Video Reverso\")\n",
    "    fechar_janela_por_titulo(\"Vizualizar Video\")\n",
    "    criar_janela_video(\"Video Reverso\")\n",
    "    \n",
    "\n",
    "    # Função interna para reproduzir os frames em ordem reversa\n",
    "def reproduzir_frames_reverso(index):\n",
    "    global frame_atual, filtro_atual, paused, frames_reverso\n",
    "    frame_processado=None\n",
    "    if not paused:\n",
    "        if index < 0:\n",
    "            index = len(frames_reverso) - 1  # Reinicia a reprodução\n",
    "        frame = frames_reverso[index]\n",
    "        if filtro_atual:\n",
    "            frame = modo_def_video(frame, filtro_atual)\n",
    "        frame_processado=normalizar_frame(frame)\n",
    "        frame_processado= cv2.cvtColor(frame_processado, cv2.COLOR_BGR2RGB)\n",
    "        frame_atual = ImageTk.PhotoImage(Image.fromarray(frame_rgb))\n",
    "    \n",
    "        # Atualiza o Canvas\n",
    "        canvas_video.create_image(0, 0, anchor=\"nw\", image=frame_atual)\n",
    "        canvas_video.img = frame_atual  # Previne garbage collection\n",
    "    \n",
    "        # Continuar reprodução\n",
    "        canvas_video.after(tempo_atual, reproduzir_frames_reverso, index - 1)\n",
    "    \n",
    "    # Função para iniciar a reprodução\n",
    "def iniciar_reproducao():\n",
    "    global frames_reverso\n",
    "    reproduzir_frames_reverso(len(frames_reverso) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be0866-a0b0-4c15-bd1e-8c7f6496a80a",
   "metadata": {},
   "source": [
    "# Função para cortar vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "addff62a-e196-4e40-a370-2b60cb1ae34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def registrar_tempo(event=None):\n",
    "    global video_capture, tempos_corte, cont_frames, cont_frames_webcam\n",
    "\n",
    "    # Obter o tempo atual do vídeo\n",
    "    print(cont_frames_webcam)\n",
    "    print(webcam_used)\n",
    "    if webcam_used:\n",
    "        tempo_atual = cont_frames_webcam\n",
    "    else:\n",
    "        tempo_atual = cont_frames\n",
    "    print(tempo_atual)\n",
    "    # Verifique se o tempo atual já está na lista para evitar duplicatas\n",
    "    if not tempos_corte or tempos_corte[-1] != tempo_atual:\n",
    "        tempos_corte.append(tempo_atual)\n",
    "        print(f\"Tempo registrado: {tempo_atual} frame\")\n",
    "    else:\n",
    "        print(f\"Tempo {tempo_atual} segundos já registrado, não adicionando novamente.\")\n",
    "\n",
    "def extrair_intervalo_frames(inicio, fim):\n",
    "    global frames_webcam\n",
    "    # Verifica se os índices estão dentro dos limites da lista\n",
    "    if inicio < 0 or fim >= len(frames_webcam) or inicio > fim:\n",
    "        print(\"Índices inválidos. Certifique-se de que 'inicio' e 'fim' estão dentro dos limites da lista de frames.\")\n",
    "        return []\n",
    "\n",
    "    # Extrai e retorna o intervalo de frames\n",
    "    return frames_webcam[inicio:fim + 1]\n",
    "\n",
    "\n",
    "def mapear_frames(inicio, fim):\n",
    "    global video_path, filtro_atual\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Verifica se o vídeo foi aberto corretamente\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erro ao abrir o vídeo.\")\n",
    "        return\n",
    "    \n",
    "    # Lista para armazenar os frames\n",
    "    frames = []\n",
    "    \n",
    "    # Define o frame inicial\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, inicio)\n",
    "    \n",
    "    # Lê os frames entre os pontos de corte\n",
    "    for frame_index in range(inicio, fim + 1):\n",
    "        ret, frame = cap.read()\n",
    "        if filtro_atual:\n",
    "            frame = modo_def_video(frame, filtro_atual)\n",
    "        frame = normalizar_frame(frame)\n",
    "        if not ret:\n",
    "            print(f\"Não foi possível ler o frame {frame_index}.\")\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    \n",
    "    # Libera o objeto de captura\n",
    "    cap.release()\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def gerar_video(frames, output_path, fps=30):\n",
    "    if not frames:\n",
    "        print(\"A lista de frames está vazia.\")\n",
    "        return\n",
    "    print(frames[0].shape)\n",
    "    # Obtém as dimensões do primeiro frame\n",
    "    height, width, _ = frames[0].shape\n",
    "    \n",
    "    # Define o codec e cria o objeto VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec para MP4\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Escreve cada frame no vídeo\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    \n",
    "    # Libera o objeto VideoWriter\n",
    "    out.release()\n",
    "    print(f\"Vídeo salvo em: {output_path}\")\n",
    "\n",
    "def gerar_videos():\n",
    "    global tempos_corte, tempo_total, video_path, webcam_used\n",
    "    \n",
    "    if webcam_used:\n",
    "        tempo_total=cont_frames_webcam;\n",
    "        \n",
    "    frames_mapeados = []\n",
    "\n",
    "    tempos_corte.append(tempo_total-1)\n",
    "\n",
    "    # Verifique os tempos de corte\n",
    "    print(f\"Tempos de corte registrados: {tempos_corte}\")\n",
    "\n",
    "    # Gerar vídeos com base nos tempos de corte\n",
    "    for i in range(len(tempos_corte) - 1):\n",
    "        start_time = tempos_corte[i]\n",
    "        end_time = tempos_corte[i + 1]\n",
    "        if(webcam_used):\n",
    "            frames_mapeados.append(extrair_intervalo_frames(start_time, end_time))\n",
    "        else:\n",
    "            frames_mapeados.append(mapear_frames(start_time, end_time))\n",
    "\n",
    "        # Gera um vídeo para cada sublista de frames\n",
    "    for i, frames in enumerate(frames_mapeados):\n",
    "        output_path = f'video_{i}.mp4'  # Define o nome do arquivo de saída\n",
    "        gerar_video(frames, output_path)\n",
    "\n",
    "    print(\"Todos os vídeos foram gerados.\")\n",
    "\n",
    "def salvar_frames():\n",
    "    global tempos_corte, webcam_used\n",
    "    if webcam_used:\n",
    "        tempo_total=cont_frames_webcam;\n",
    "    tempos_corte.append(tempo_total-1)\n",
    "    # Itera sobre os tempos de corte para salvar os frames\n",
    "    for i in range(len(tempos_corte) - 1):\n",
    "        start_time = tempos_corte[i]\n",
    "        end_time = tempos_corte[i + 1]\n",
    "        \n",
    "        # Define o nome da pasta para o conjunto atual\n",
    "        pasta_destino = f'frames_salvos_{i + 1}'\n",
    "        \n",
    "        # Se a pasta já existir, remove-a para sobrescrever\n",
    "        if os.path.exists(pasta_destino):\n",
    "            shutil.rmtree(pasta_destino)  # Remove a pasta e seu conteúdo\n",
    "        \n",
    "        # Cria a nova pasta de destino\n",
    "        os.makedirs(pasta_destino)\n",
    "        print(f\"Pasta '{pasta_destino}' criada ou sobrescrita.\")\n",
    "        \n",
    "        if webcam_used:\n",
    "            frames = extrair_intervalo_frames(start_time, end_time)\n",
    "        else:\n",
    "            frames = mapear_frames(start_time, end_time)\n",
    "        \n",
    "        # Salva cada frame na pasta de destino\n",
    "        for j, frame in enumerate(frames):\n",
    "            if frame is not None:  # Verifica se o frame não é None\n",
    "                # Define o nome do arquivo\n",
    "                nome_arquivo = os.path.join(pasta_destino, f'frame_{start_time + j}.png')\n",
    "                # Salva o frame como uma imagem\n",
    "                cv2.imwrite(nome_arquivo, frame)\n",
    "                print(f'Salvo: {nome_arquivo}')\n",
    "            else:\n",
    "                print(f'Frame {start_time + j} é None e não será salvo.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f6eb1-ac78-428e-a6ce-02ad2c2f0185",
   "metadata": {},
   "source": [
    "# Função Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd8efd-5575-4f7d-b6c0-d47213249f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    abrirJanelaPrincipal().mainloop()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1326fb-4d14-4c14-8e5a-93366133c5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be84a0-d177-4486-868c-1d6cfd762f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5269515-d0f9-4731-a803-f401517fbb58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
